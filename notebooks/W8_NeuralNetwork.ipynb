{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Neuron Network model to predict stock daily return rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0=all, 1=info, 2=warning, 3=error\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore all future warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6423 entries, 0 to 6422\n",
      "Data columns (total 31 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   DTYYYYMMDD            6423 non-null   object \n",
      " 1   Ticker                6423 non-null   object \n",
      " 2   Open                  6423 non-null   float64\n",
      " 3   High                  6423 non-null   float64\n",
      " 4   Low                   6423 non-null   float64\n",
      " 5   Close                 6423 non-null   float64\n",
      " 6   Volume                6423 non-null   float64\n",
      " 7   Outlier               6423 non-null   bool   \n",
      " 8   daily_returns         6423 non-null   float64\n",
      " 9   monthly_returns       6423 non-null   float64\n",
      " 10  yearly_returns        6423 non-null   float64\n",
      " 11  Net_advances          6423 non-null   int64  \n",
      " 12  A/D                   6423 non-null   float64\n",
      " 13  Schultz               6423 non-null   float64\n",
      " 14  EMA19_net_adv         6423 non-null   float64\n",
      " 15  EMA39_net_adv         6423 non-null   float64\n",
      " 16  McClellan_Oscillator  6423 non-null   float64\n",
      " 17  TRIN                  6423 non-null   float64\n",
      " 18  StockAboveMA50        6423 non-null   int64  \n",
      " 19  MA5                   6423 non-null   float64\n",
      " 20  EMA5                  6423 non-null   float64\n",
      " 21  MA10                  6423 non-null   float64\n",
      " 22  EMA10                 6423 non-null   float64\n",
      " 23  MA20                  6423 non-null   float64\n",
      " 24  EMA20                 6423 non-null   float64\n",
      " 25  MA50                  6423 non-null   float64\n",
      " 26  EMA50                 6423 non-null   float64\n",
      " 27  MA100                 6423 non-null   float64\n",
      " 28  EMA100                6423 non-null   float64\n",
      " 29  MA200                 6423 non-null   float64\n",
      " 30  EMA200                6423 non-null   float64\n",
      "dtypes: bool(1), float64(26), int64(2), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/VNINDEX_add_features.csv')\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      daily_returns  Net_advances       A/D   Schultz  EMA19_net_adv  EMA39_net_adv  McClellan_Oscillator      TRIN  StockAboveMA50       MA5      EMA5      MA10     EMA10      MA20     EMA20      MA50     EMA50     MA100    EMA100     MA200    EMA200\n",
      "daily_returns              1.000000      0.629682  0.385782  0.360136       0.304914       0.221159              0.357898 -0.045105        0.078571 -0.025212 -0.021846 -0.030325 -0.027663 -0.034325 -0.032604 -0.040646 -0.038338 -0.042650 -0.041812 -0.044733 -0.044045\n",
      "Net_advances               0.629682      1.000000  0.499066  0.634140       0.443493       0.321071              0.521660 -0.027070        0.148104  0.025248  0.027990  0.022683  0.024633  0.021810  0.022581  0.019807  0.020557  0.018636  0.019296  0.017505  0.019351\n",
      "A/D                        0.385782      0.499066  1.000000  0.428697       0.156179       0.102137              0.203736 -0.022393        0.111282  0.114891  0.116383  0.115240  0.116160  0.117770  0.117590  0.121462  0.120858  0.123548  0.124944  0.132055  0.133227\n",
      "Schultz                    0.360136      0.634140  0.428697  1.000000       0.392185       0.364990              0.312762 -0.058570        0.708397  0.676031  0.677782  0.674957  0.676389  0.675334  0.676407  0.676808  0.679089  0.680650  0.685001  0.689259  0.697977\n",
      "EMA19_net_adv              0.304914      0.443493  0.156179  0.392185       1.000000       0.939982              0.780397 -0.018073        0.550710  0.152533  0.153769  0.136272  0.139999  0.115824  0.122806  0.090193  0.099301  0.076514  0.084760  0.067356  0.077902\n",
      "EMA39_net_adv              0.221159      0.321071  0.102137  0.364990       0.939982       1.000000              0.520197 -0.017530        0.645925  0.223450  0.223961  0.209242  0.211216  0.186948  0.192006  0.147236  0.158389  0.118170  0.132637  0.097863  0.116329\n",
      "McClellan_Oscillator       0.357898      0.521660  0.203736  0.312762       0.780397       0.520197              1.000000 -0.013112        0.194725 -0.027694 -0.025536 -0.042357 -0.036647 -0.052682 -0.044477 -0.044063 -0.041705 -0.025037 -0.030909 -0.010746 -0.018189\n",
      "TRIN                      -0.045105     -0.027070 -0.022393 -0.058570      -0.018073      -0.017530             -0.013112  1.000000       -0.047645 -0.058525 -0.058657 -0.058334 -0.058428 -0.058038 -0.058152 -0.057376 -0.057563 -0.056296 -0.056965 -0.055740 -0.056546\n",
      "StockAboveMA50             0.078571      0.148104  0.111282  0.708397       0.550710       0.645925              0.194725 -0.047645        1.000000  0.706297  0.706419  0.699132  0.699762  0.685772  0.688600  0.659139  0.670629  0.651220  0.663059  0.652874  0.668165\n",
      "MA5                       -0.025212      0.025248  0.114891  0.676031       0.152533       0.223450             -0.027694 -0.058525        0.706297  1.000000  0.999970  0.999617  0.999759  0.998070  0.998698  0.991859  0.994204  0.980215  0.985614  0.955452  0.968141\n",
      "EMA5                      -0.021846      0.027990  0.116383  0.677782       0.153769       0.223961             -0.025536 -0.058657        0.706419  0.999970  1.000000  0.999623  0.999787  0.998157  0.998762  0.992000  0.994322  0.980378  0.985760  0.955622  0.968304\n",
      "MA10                      -0.030325      0.022683  0.115240  0.674957       0.136272       0.209242             -0.042357 -0.058334        0.699132  0.999617  0.999623  1.000000  0.999935  0.999136  0.999461  0.993540  0.995619  0.982114  0.987372  0.957528  0.970097\n",
      "EMA10                     -0.027663      0.024633  0.116160  0.676389       0.139999       0.211216             -0.036647 -0.058428        0.699762  0.999759  0.999787  0.999935  1.000000  0.999156  0.999525  0.993773  0.995800  0.982450  0.987648  0.957903  0.970437\n",
      "MA20                      -0.034325      0.021810  0.117770  0.675334       0.115824       0.186948             -0.052682 -0.058038        0.685772  0.998070  0.998157  0.999136  0.999156  1.000000  0.999854  0.996365  0.997722  0.985703  0.990479  0.961619  0.973820\n",
      "EMA20                     -0.032604      0.022581  0.117590  0.676407       0.122806       0.192006             -0.044477 -0.058152        0.688600  0.998698  0.998762  0.999461  0.999525  0.999854  1.000000  0.996518  0.997911  0.986269  0.990888  0.962369  0.974442\n",
      "MA50                      -0.040646      0.019807  0.121462  0.676808       0.090193       0.147236             -0.044063 -0.057376        0.659139  0.991859  0.992000  0.993540  0.993773  0.996365  0.996518  1.000000  0.999556  0.994298  0.996644  0.972973  0.983211\n",
      "EMA50                     -0.038338      0.020557  0.120858  0.679089       0.099301       0.158389             -0.041705 -0.057563        0.670629  0.994204  0.994322  0.995619  0.995800  0.997722  0.997911  0.999556  1.000000  0.994435  0.997070  0.974309  0.984196\n",
      "MA100                     -0.042650      0.018636  0.123548  0.680650       0.076514       0.118170             -0.025037 -0.056296        0.651220  0.980215  0.980378  0.982114  0.982450  0.985703  0.986269  0.994298  0.994435  1.000000  0.998968  0.987906  0.993246\n",
      "EMA100                    -0.041812      0.019296  0.124944  0.685001       0.084760       0.132637             -0.030909 -0.056965        0.663059  0.985614  0.985760  0.987372  0.987648  0.990479  0.990888  0.996644  0.997070  0.998968  1.000000  0.988054  0.994154\n",
      "MA200                     -0.044733      0.017505  0.132055  0.689259       0.067356       0.097863             -0.010746 -0.055740        0.652874  0.955452  0.955622  0.957528  0.957903  0.961619  0.962369  0.972973  0.974309  0.987906  0.988054  1.000000  0.997615\n",
      "EMA200                    -0.044045      0.019351  0.133227  0.697977       0.077902       0.116329             -0.018189 -0.056546        0.668165  0.968141  0.968304  0.970097  0.970437  0.973820  0.974442  0.983211  0.984196  0.993246  0.994154  0.997615  1.000000\n"
     ]
    }
   ],
   "source": [
    "## Caculate the correlation matrix of the features\n",
    "corr_df = df.copy()\n",
    "corr_df = corr_df.drop(columns=['DTYYYYMMDD','Ticker','Open','High','Low','Volume','Close','Outlier','monthly_returns','yearly_returns'])\n",
    "corr_matrix = corr_df.corr()\n",
    "\n",
    "## Display the correlation matrix\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)  # ngăn DataFrame xuống dòng\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "print(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So when we analyze the correlation matrix, we decide to use the features: Net_advances,A/D,Schultz, and McClellan_Oscillator\n",
    "selected_features = ['Net_advances','A/D','Schultz','McClellan_Oscillator']\n",
    "target_feature = ['daily_returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_advances           -95.000000\n",
      "A/D                      0.000000\n",
      "Schultz                  0.000000\n",
      "McClellan_Oscillator   -12.763631\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Net_advances            94.000000\n",
      "A/D                     93.000000\n",
      "Schultz                  0.989474\n",
      "McClellan_Oscillator    16.172283\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[selected_features].min())\n",
    "print('\\n')\n",
    "print(df[selected_features].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since these data was cleaned and had no outliers , we can use MinMaxScaler to scale the data\n",
    "# The data range is from 0 to 1\n",
    "scaler = MinMaxScaler()\n",
    "df[selected_features] = scaler.fit_transform(df[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_advances            0.0\n",
      "A/D                     0.0\n",
      "Schultz                 0.0\n",
      "McClellan_Oscillator    0.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Net_advances            1.0\n",
      "A/D                     1.0\n",
      "Schultz                 1.0\n",
      "McClellan_Oscillator    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[selected_features].min())\n",
    "print('\\n')\n",
    "print(df[selected_features].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and predict with Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\cuda11-cudnn8-tensorflow\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6423, 4)\n",
      "(6423,)\n"
     ]
    }
   ],
   "source": [
    "# Get the absolute path of the `src` folder\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\"))\n",
    "# Add `src` to the system path\n",
    "sys.path.insert(0, src_path)\n",
    "# Import \n",
    "from models.DecisionTree import prepare_data_for_decision_tree\n",
    "\n",
    "X,y = prepare_data_for_decision_tree(df, selected_features, target_feature,method_to_create_threshold='up_and_down')\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "split_index = int(len(X) * 0.8)  # Calculate the 80% split index\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train,y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([0, 1, 2], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because sparse_categorical_crossentropy is used, the labels should be in the range of 0 to num_classes - 1\n",
    "# Convert y_train and y_test to positive integer labels\n",
    "y_train = y_train + 1\n",
    "y_test = y_test + 1\n",
    "np.unique(y_train),np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 1.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to one-hot encoding\n",
    "y_train = tf.one_hot(y_train, depth=3)\n",
    "y_test = tf.one_hot(y_test, depth=3)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking X_train for NaN or Inf values: False False\n",
      "Checking y_train for NaN or Inf values: False False\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN or Inf values in the training data\n",
    "print(\"Checking X_train for NaN or Inf values:\", np.any(np.isnan(X_train)), np.any(np.isinf(X_train)))\n",
    "print(\"Checking y_train for NaN or Inf values:\", np.any(np.isnan(y_train)), np.any(np.isinf(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                320       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1411 (5.51 KB)\n",
      "Trainable params: 1411 (5.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "161/161 [==============================] - 0s 716us/step - loss: 0.9711 - accuracy: 0.5197\n",
      "Epoch 2/50\n",
      "161/161 [==============================] - 0s 612us/step - loss: 0.9182 - accuracy: 0.5453\n",
      "Epoch 3/50\n",
      "161/161 [==============================] - 0s 604us/step - loss: 0.9012 - accuracy: 0.5452\n",
      "Epoch 4/50\n",
      "161/161 [==============================] - 0s 606us/step - loss: 0.8939 - accuracy: 0.5450\n",
      "Epoch 5/50\n",
      "161/161 [==============================] - 0s 659us/step - loss: 0.8923 - accuracy: 0.5453\n",
      "Epoch 6/50\n",
      "161/161 [==============================] - 0s 609us/step - loss: 0.8887 - accuracy: 0.5452\n",
      "Epoch 7/50\n",
      "161/161 [==============================] - 0s 598us/step - loss: 0.8877 - accuracy: 0.5446\n",
      "Epoch 8/50\n",
      "161/161 [==============================] - 0s 599us/step - loss: 0.8842 - accuracy: 0.5457\n",
      "Epoch 9/50\n",
      "161/161 [==============================] - 0s 608us/step - loss: 0.8829 - accuracy: 0.5455\n",
      "Epoch 10/50\n",
      "161/161 [==============================] - 0s 587us/step - loss: 0.8807 - accuracy: 0.5446\n",
      "Epoch 11/50\n",
      "161/161 [==============================] - 0s 580us/step - loss: 0.8801 - accuracy: 0.5473\n",
      "Epoch 12/50\n",
      "161/161 [==============================] - 0s 582us/step - loss: 0.8795 - accuracy: 0.5477\n",
      "Epoch 13/50\n",
      "161/161 [==============================] - 0s 613us/step - loss: 0.8780 - accuracy: 0.5467\n",
      "Epoch 14/50\n",
      "161/161 [==============================] - 0s 606us/step - loss: 0.8773 - accuracy: 0.5469\n",
      "Epoch 15/50\n",
      "161/161 [==============================] - 0s 610us/step - loss: 0.8760 - accuracy: 0.5477\n",
      "Epoch 16/50\n",
      "161/161 [==============================] - 0s 591us/step - loss: 0.8758 - accuracy: 0.5504\n",
      "Epoch 17/50\n",
      "161/161 [==============================] - 0s 595us/step - loss: 0.8744 - accuracy: 0.5492\n",
      "Epoch 18/50\n",
      "161/161 [==============================] - 0s 598us/step - loss: 0.8739 - accuracy: 0.5494\n",
      "Epoch 19/50\n",
      "161/161 [==============================] - 0s 600us/step - loss: 0.8734 - accuracy: 0.5494\n",
      "Epoch 20/50\n",
      "161/161 [==============================] - 0s 595us/step - loss: 0.8732 - accuracy: 0.5518\n",
      "Epoch 21/50\n",
      "161/161 [==============================] - 0s 665us/step - loss: 0.8725 - accuracy: 0.5529\n",
      "Epoch 22/50\n",
      "161/161 [==============================] - 0s 618us/step - loss: 0.8712 - accuracy: 0.5568\n",
      "Epoch 23/50\n",
      "161/161 [==============================] - 0s 620us/step - loss: 0.8726 - accuracy: 0.5576\n",
      "Epoch 24/50\n",
      "161/161 [==============================] - 0s 621us/step - loss: 0.8715 - accuracy: 0.5566\n",
      "Epoch 25/50\n",
      "161/161 [==============================] - 0s 614us/step - loss: 0.8700 - accuracy: 0.5557\n",
      "Epoch 26/50\n",
      "161/161 [==============================] - 0s 589us/step - loss: 0.8706 - accuracy: 0.5539\n",
      "Epoch 27/50\n",
      "161/161 [==============================] - 0s 599us/step - loss: 0.8713 - accuracy: 0.5557\n",
      "Epoch 28/50\n",
      "161/161 [==============================] - 0s 598us/step - loss: 0.8721 - accuracy: 0.5537\n",
      "Epoch 29/50\n",
      "161/161 [==============================] - 0s 611us/step - loss: 0.8705 - accuracy: 0.5559\n",
      "Epoch 30/50\n",
      "161/161 [==============================] - 0s 606us/step - loss: 0.8696 - accuracy: 0.5524\n",
      "Epoch 31/50\n",
      "161/161 [==============================] - 0s 605us/step - loss: 0.8696 - accuracy: 0.5553\n",
      "Epoch 32/50\n",
      "161/161 [==============================] - 0s 740us/step - loss: 0.8693 - accuracy: 0.5537\n",
      "Epoch 33/50\n",
      "161/161 [==============================] - 0s 831us/step - loss: 0.8702 - accuracy: 0.5576\n",
      "Epoch 34/50\n",
      "161/161 [==============================] - 0s 673us/step - loss: 0.8691 - accuracy: 0.5607\n",
      "Epoch 35/50\n",
      "161/161 [==============================] - 0s 669us/step - loss: 0.8692 - accuracy: 0.5631\n",
      "Epoch 36/50\n",
      "161/161 [==============================] - 0s 593us/step - loss: 0.8699 - accuracy: 0.5557\n",
      "Epoch 37/50\n",
      "161/161 [==============================] - 0s 589us/step - loss: 0.8687 - accuracy: 0.5557\n",
      "Epoch 38/50\n",
      "161/161 [==============================] - 0s 576us/step - loss: 0.8679 - accuracy: 0.5580\n",
      "Epoch 39/50\n",
      "161/161 [==============================] - 0s 563us/step - loss: 0.8677 - accuracy: 0.5607\n",
      "Epoch 40/50\n",
      "161/161 [==============================] - 0s 595us/step - loss: 0.8681 - accuracy: 0.5642\n",
      "Epoch 41/50\n",
      "161/161 [==============================] - 0s 623us/step - loss: 0.8678 - accuracy: 0.5576\n",
      "Epoch 42/50\n",
      "161/161 [==============================] - 0s 594us/step - loss: 0.8672 - accuracy: 0.5584\n",
      "Epoch 43/50\n",
      "161/161 [==============================] - 0s 647us/step - loss: 0.8664 - accuracy: 0.5642\n",
      "Epoch 44/50\n",
      "161/161 [==============================] - 0s 683us/step - loss: 0.8666 - accuracy: 0.5638\n",
      "Epoch 45/50\n",
      "161/161 [==============================] - 0s 636us/step - loss: 0.8666 - accuracy: 0.5611\n",
      "Epoch 46/50\n",
      "161/161 [==============================] - 0s 599us/step - loss: 0.8670 - accuracy: 0.5580\n",
      "Epoch 47/50\n",
      "161/161 [==============================] - 0s 595us/step - loss: 0.8661 - accuracy: 0.5594\n",
      "Epoch 48/50\n",
      "161/161 [==============================] - 0s 599us/step - loss: 0.8655 - accuracy: 0.5660\n",
      "Epoch 49/50\n",
      "161/161 [==============================] - 0s 599us/step - loss: 0.8647 - accuracy: 0.5646\n",
      "Epoch 50/50\n",
      "161/161 [==============================] - 0s 647us/step - loss: 0.8653 - accuracy: 0.5603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16fc7012fe0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 626us/step\n",
      "[[0.6000139  0.22848697 0.1714991 ]\n",
      " [0.4543155  0.45965528 0.08602925]\n",
      " [0.671872   0.06139563 0.2667323 ]\n",
      " ...\n",
      " [0.6606307  0.08292524 0.256444  ]\n",
      " [0.672902   0.04622131 0.2808768 ]\n",
      " [0.67648065 0.14650048 0.17701888]]\n",
      "Score: 0.574319064617157\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "print('Score:', model.evaluate(X_test, y_test, verbose=0)[1])\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred = y_pred -1\n",
    "y_predict = np.pad(y_pred,(len(y_train),0),'constant',constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade with the predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "2004413.8835999998\n",
      "Total profit: 4413.883599999826\n",
      "Total trade number: 9\n",
      "Win rate: 0.5555555555555556\n",
      "Profit factor: 1.8683589738787425\n"
     ]
    }
   ],
   "source": [
    "from trade_stocks.trade import Trading\n",
    "\n",
    "trading = Trading()\n",
    "trade_signal = trading.generate_trade_signal(y_predict)\n",
    "print(trade_signal)\n",
    "finally_capital = trading.execute_trade(trade_signal,np.array(df['Close']))\n",
    "print(finally_capital)\n",
    "total_profit,total_trade_number,win_rate,profit_factor = trading.performance()\n",
    "\n",
    "print(f\"Total profit: {total_profit}\")\n",
    "print(f\"Total trade number: {total_trade_number}\")\n",
    "print(f\"Win rate: {win_rate}\")\n",
    "print(f\"Profit factor: {profit_factor}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda11-cudnn8-tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
